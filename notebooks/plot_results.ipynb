{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.utils.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"lattice\"\n",
    "data_id_choices = [\"lattice\", \"greater\", \"family_tree\", \"equivalence\", \"circle\", \"permutation\"]\n",
    "model_id_choices = [\"H_MLP\", \"standard_MLP\", \"H_transformer\", \"standard_transformer\"]\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 66\n",
    "# data_id = \"lattice\"\n",
    "data_size = 1000\n",
    "train_ratio = 0.8\n",
    "\n",
    "data_size_list = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "\n",
    "for model_id in model_id_choices:\n",
    "    metric_list = []\n",
    "    for data_size in data_size_list:\n",
    "        fname = f'../results/{seed}_{data_id}_{model_id}_{data_size}_{train_ratio}.json'\n",
    "        with open(fname, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            metric_list.append(data['metric'])\n",
    "            if data_size == 1000:\n",
    "                print(model_id, data['variances'][0] + data['variances'][1])\n",
    "        fname = f'../results/{seed}_{data_id}_{model_id}_{data_size}_{train_ratio}_train_results.json'\n",
    "        with open(fname, 'r') as file:\n",
    "            data = json.load(file)\n",
    "#            metric_list.append(data['test_accuracies'][-1])\n",
    "    plt.plot(data_size_list, metric_list, '-o', label=model_id)\n",
    "\n",
    "plt.legend()\n",
    "import numpy as np\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "train_ratio_list = np.arange(1, 10) / 10\n",
    "data_size = 1000\n",
    "\n",
    "for model_id in model_id_choices:\n",
    "    metric_list = []\n",
    "    for train_ratio in train_ratio_list:\n",
    "        fname = f'../results/{seed}_{data_id}_{model_id}_{data_size}_{train_ratio}.json'\n",
    "        with open(fname, 'r') as file:\n",
    "            data = json.load(file)\n",
    "#            metric_list.append(data['metric'])\n",
    "        fname = f'../results/{seed}_{data_id}_{model_id}_{data_size}_{train_ratio}_train_results.json'\n",
    "        with open(fname, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            metric_list.append(data['test_accuracies'][-1])\n",
    "    plt.plot(train_ratio_list, metric_list, '-o', label=model_id,linewidth=3,markersize=10)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Train Fraction')\n",
    "plt.ylabel('Test Accuracy')\n",
    "\n",
    "data_id_to_title = {\n",
    "    \"lattice\": \"In-context Learning\",\n",
    "    \"greater\": \"Greater\",\n",
    "    \"family_tree\": \"Genealogy Learning\",\n",
    "    \"equivalence\": \"Equivalence Classes\",\n",
    "    \"circle\": \"Modular Addition\",\n",
    "    \"permutation\": \"Permutation Composition\"\n",
    "}\n",
    "plt.title(data_id_to_title[data_id])\n",
    "plt.savefig(\"../riya_figs/fig_eff.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "seed=66\n",
    "train_ratio = 0.8\n",
    "data_size = 1000\n",
    "embd_dim = 16\n",
    "\n",
    "for model_id in model_id_choices:\n",
    "    fname = f'../results/{seed}_{data_id}_{model_id}_{data_size}_{train_ratio}.json'\n",
    "    try:\n",
    "        with open(fname, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            metric_list = data['variances']\n",
    "    except FileNotFoundError: # Riya: I trained some models without using run_exp.py so did not save variances in .json\n",
    "        model = load_model_from_file(model_id, data_id, data_size=data_size, train_ratio=train_ratio, seed=seed)\n",
    "        embd = model.embedding.cpu().detach().numpy() if 'MLP' in model_id else model.embedding.weight.cpu().detach().numpy()\n",
    "        X = embd\n",
    "        pca = PCA(n_components=embd_dim) \n",
    "        pca.fit(X)\n",
    "        embd_t = pca.fit_transform(X)\n",
    "        metric_list = pca.explained_variance_ratio_\n",
    "\n",
    "    plt.plot(range(16), np.cumsum(np.array(metric_list))[:16], '-o', label=model_id,linewidth=3,markersize=10)\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks(range(16))\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "\n",
    "data_id_to_title = {\n",
    "    \"lattice\": \"In-context Learning\",\n",
    "    \"greater\": \"Greater\",\n",
    "    \"family_tree\": \"Genealogy Learning\",\n",
    "    \"equivalence\": \"Equivalence Classes\",\n",
    "    \"circle\": \"Modular Addition\",\n",
    "    \"permutation\": \"Permutation Composition\"\n",
    "}\n",
    "plt.title(data_id_to_title[data_id])\n",
    "plt.savefig(\"../riya_figs/perm_eff.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 66\n",
    "plt.figure(figsize=(10, 6))\n",
    "for model_id in [\"H_MLP\", \"standard_MLP\"]:\n",
    "\n",
    "    data_size = 1000\n",
    "    train_ratio = 0.8\n",
    "\n",
    "    # Load the .pt file\n",
    "    weights = torch.load(f\"../results/{seed}_{data_id}_{model_id}_{data_size}_{train_ratio}.pt\")\n",
    "\n",
    "    # Check the structure of the file (if necessary)\n",
    "    print(type(weights))\n",
    "    if isinstance(weights, dict):\n",
    "        print(weights.keys())  # See the keys in the dictionary\n",
    "\n",
    "    # Collect all weights into a list\n",
    "    all_weights = []\n",
    "\n",
    "    for key, value in weights.items():\n",
    "        if 'dist' not in key and isinstance(value, torch.Tensor):  # Ensure it's a tensor\n",
    "            all_weights.extend(value.flatten().tolist())\n",
    "\n",
    "    # Plot histogram\n",
    "    \n",
    "    plt.hist(all_weights, range=(-3,3),bins=100, edgecolor='k', alpha=0.7, label=model_id)\n",
    "plt.title(\"Histogram of All Layer Weights\")\n",
    "plt.xlabel(\"Weight Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = np.linspace(0, 1000, 20, dtype=int)[:4]\n",
    "model_id = \"standard_transformer\"\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "for seed in seed_list:\n",
    "    fname = f'../results/{seed}_{data_id}_{model_id}_{data_size}_{train_ratio}_train_results.json'\n",
    "    with open(fname, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        train_acc_list.append(data['train_accuracies'])\n",
    "        test_acc_list.append(data['test_accuracies'])\n",
    "        print(train_acc_list[-1][-1], test_acc_list[-1][-1])\n",
    "\n",
    "train_acc_list = torch.tensor(train_acc_list)\n",
    "test_acc_list = torch.tensor(test_acc_list)\n",
    "\n",
    "print(train_acc_list.shape, test_acc_list.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(range(train_acc_list.shape[1]), torch.mean(train_acc_list, dim=0), torch.std(train_acc_list, dim=0), label='Train')\n",
    "#plt.errorbar(range(test_acc_list.shape[1]), torch.mean(test_acc_list, dim=0), torch.std(test_acc_list, dim=0), label='Test')\n",
    "#plt.xlim(0,20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = np.linspace(0, 1000, 20, dtype=int)\n",
    "model_id = \"standard_MLP\"\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "for seed in seed_list:\n",
    "    fname = f'../results/{seed}_{data_id}_{model_id}_{data_size}_{train_ratio}_train_results.json'\n",
    "    with open(fname, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        train_acc_list.append(data['train_accuracies'])\n",
    "        test_acc_list.append(data['test_accuracies'])\n",
    "\n",
    "train_acc_list = torch.tensor(train_acc_list)\n",
    "test_acc_list = torch.tensor(test_acc_list)\n",
    "\n",
    "print(train_acc_list.shape, test_acc_list.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(range(train_acc_list.shape[1]), torch.mean(train_acc_list, dim=0), torch.std(train_acc_list, dim=0), label='Train')\n",
    "plt.errorbar(range(test_acc_list.shape[1]), torch.mean(test_acc_list, dim=0), torch.std(test_acc_list, dim=0), label='Test')\n",
    "plt.xlim(0,1000)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = np.linspace(0, 1000, 20, dtype=int)\n",
    "data_id = \"permutation\"\n",
    "thres = 0.9\n",
    "train_ratio = 0.8\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "max_idx = 0\n",
    "model_id = \"standard_transformer\"\n",
    "model_1 = model_id\n",
    "for seed in seed_list:\n",
    "    fname = f'../results/{seed}_{data_id}_{model_id}_{data_size}_{train_ratio}_train_results.json'\n",
    "    with open(fname, 'r') as file:\n",
    "        try:\n",
    "            data = json.load(file)\n",
    "            train_acc_list.append(data['train_accuracies'])\n",
    "            test_acc_list.append(data['test_accuracies'])\n",
    "            idx_train = np.argmax(np.array(data['train_accuracies']) > thres)\n",
    "            idx_test = np.argmax(np.array(data['test_accuracies']) > thres)\n",
    "            if idx_train > max_idx:\n",
    "                max_idx = idx_train\n",
    "            if idx_test > max_idx:\n",
    "                max_idx = idx_test\n",
    "            plt.scatter([idx_train], [idx_test], c='r')\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "model_id = \"H_transformer\"\n",
    "model_2 = model_id\n",
    "for seed in seed_list:\n",
    "    fname = f'../results/{seed}_{data_id}_{model_id}_{data_size}_{train_ratio}_train_results.json'\n",
    "    with open(fname, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        train_acc_list.append(data['train_accuracies'])\n",
    "        test_acc_list.append(data['test_accuracies'])\n",
    "        idx_train = np.argmax(np.array(data['train_accuracies']) > thres)\n",
    "        idx_test = np.argmax(np.array(data['test_accuracies']) > thres)\n",
    "        plt.scatter(idx_train, idx_test, c='b')\n",
    "        if idx_train > max_idx:\n",
    "            max_idx = idx_train\n",
    "        if idx_test > max_idx:\n",
    "            max_idx = idx_test\n",
    "\n",
    "plt.plot(range(max_idx+1), range(max_idx+1), 'k--')\n",
    "plt.xlabel('Epochs to Train Acc > {}'.format(thres))\n",
    "plt.ylabel('Epochs to Test Acc > {}'.format(thres))\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "legend_handles = [\n",
    "    Line2D([0], [0], marker='o', color='w', label=model_1, markerfacecolor='red', markersize=10),\n",
    "    Line2D([0], [0], marker='o', color='w', label=model_2, markerfacecolor='blue', markersize=10)\n",
    "]\n",
    "plt.legend(handles=legend_handles)\n",
    "data_id_to_title = {\n",
    "    \"lattice\": \"In-context Learning\",\n",
    "    \"greater\": \"Greater\",\n",
    "    \"family_tree\": \"Genealogy Learning\",\n",
    "    \"equivalence\": \"Equivalence Classes\",\n",
    "    \"circle\": \"Modular Addition\",\n",
    "    \"permutation\": \"Permutation Composition\"\n",
    "}\n",
    "plt.title(data_id_to_title[data_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a 16x20 grid of subplots\n",
    "fig, axes = plt.subplots(16, 20, figsize=(20, 16))\n",
    "\n",
    "data_id_choices = [\"lattice\", \"family_tree\", \"equivalence\", \"circle\", \"permutation\"]\n",
    "model_id_choices = [\"standard_MLP\",\"H_MLP\", \"standard_transformer\",\"H_transformer\"]\n",
    "\n",
    "colors = ['r', 'g', 'b', 'y', 'm', 'c', 'k', 'w']\n",
    "\n",
    "seed_list = np.linspace(0, 1000, 20, dtype=int)\n",
    "\n",
    "dict_level = dict()\n",
    "dict_level[1] = 0\n",
    "for i in range(1,127):\n",
    "    if (2*i) < 127:\n",
    "        dict_level[2*i] = dict_level[i] + 1\n",
    "    if (2*i + 1) < 127:\n",
    "        dict_level[2*i + 1] = dict_level[i] + 1\n",
    "\n",
    "# Add labels for rows and columns\n",
    "for i, ax_row in enumerate(axes):\n",
    "    for j, ax in enumerate(ax_row):\n",
    "        \n",
    "        # Remove ticks for clarity\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        data_id = data_id_choices[i // 4]\n",
    "        model_id = model_id_choices[i % 4]\n",
    "        seed = seed_list[j]\n",
    "\n",
    "        weights = torch.load(f\"../results/{seed}_{data_id}_{model_id}_{data_size}_{train_ratio}.pt\")\n",
    "        if 'MLP' in model_id:\n",
    "            emb = weights['embedding']\n",
    "        else:\n",
    "            emb = weights['embedding.weight']\n",
    "\n",
    "        if \"family\" in data_id:\n",
    "            emb = emb[1:127]\n",
    "\n",
    "        pca = PCA(n_components=2)\n",
    "        pca_emb = pca.fit_transform(emb.cpu())\n",
    "        if i != 0:\n",
    "            ax.set_title(f'EV: {(pca.explained_variance_ratio_[0] + pca.explained_variance_ratio_[1])*100: .0f}%',fontsize=8)\n",
    "        else:\n",
    "            ax.set_xlabel(f'EV: {(pca.explained_variance_ratio_[0] + pca.explained_variance_ratio_[1])*100: .0f}%',fontsize=8)\n",
    "            ax.xaxis.set_label_position('top')\n",
    "\n",
    "        if \"family\" in data_id:\n",
    "            for kk in range(1,127):\n",
    "                ax.scatter(pca_emb[kk-1, 0], pca_emb[kk-1, 1], c=colors[dict_level[kk]])\n",
    "        else:\n",
    "            ax.scatter(pca_emb[:, 0], pca_emb[:, 1])\n",
    "        \n",
    "        \n",
    "        # Label the first column with row numbers\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f'{data_id}\\n{model_id}', rotation=0, labelpad=30, fontsize=8, ha='right', va='center')\n",
    "        \n",
    "        # Label the last row with column numbers\n",
    "        if i == 0:\n",
    "            ax.set_title(f'Seed {seed}', fontsize=8)\n",
    "#            ax.xaxis.set_label_position('top')  # Place column labels at the top\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae-exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
