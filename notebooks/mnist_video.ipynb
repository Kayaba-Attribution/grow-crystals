{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") \n",
    "\n",
    "from src.utils.driver import set_seed\n",
    "\n",
    "set_seed(57)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "from src.utils.model import DistLayer\n",
    "\n",
    "# Define the model class\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, harmonic=False):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.harmonic = harmonic\n",
    "        if harmonic:\n",
    "            self.fc1 = DistLayer(28 * 28, 10, n=1.)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(28 * 28, 10)\n",
    "        nn.init.normal_(self.fc1.weight, mean=0, std=1/28.)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the input\n",
    "        x = self.fc1(x)\n",
    "        if self.harmonic:\n",
    "            prob = x/torch.sum(x, dim=1, keepdim=True)\n",
    "            logits = (-1)*torch.log(prob)\n",
    "            return logits\n",
    "        return x\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "max_epochs = 100\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "def save_weight_visualization_gif(model, train_loader, test_loader, \n",
    "                                   max_epochs=100, \n",
    "                                   learning_rate=0.001, \n",
    "                                   device='cuda', \n",
    "                                   output_dir='../results/mnist_vis',\n",
    "                                   save_prefix='',\n",
    "                                   selected_classes=[3, 5, 7, 9]):\n",
    "    \"\"\"\n",
    "    Train the model and save weight visualizations as a GIF\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Neural network model\n",
    "        train_loader (DataLoader): Training data loader\n",
    "        test_loader (DataLoader): Test data loader\n",
    "        max_epochs (int): Maximum number of training epochs\n",
    "        learning_rate (float): Learning rate for optimizer\n",
    "        device (str): Training device (cuda/cpu)\n",
    "        output_dir (str): Directory to save visualizations\n",
    "        selected_classes (list): Classes to visualize\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Optimizer and loss\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Visualization storage\n",
    "    weight_images = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in [1]:\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            loss = outputs[range(targets.size(0)), targets].mean()\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            # Periodically save weight visualization\n",
    "            if (batch_idx+1) % 10 == 0:\n",
    "                \n",
    "                plt.figure(figsize=(16, 12))\n",
    "                plt.suptitle(f'Weight Visualization - Epoch {epoch}')\n",
    "                \n",
    "                for i, cls in enumerate(selected_classes, 1):\n",
    "                    # Extract weights for specific class\n",
    "                    weights = model.fc1.weight.detach().cpu().numpy()[cls].reshape(28, 28)\n",
    "                    weights = np.where(weights < 0.01, 1, 0)\n",
    "                    \n",
    "                    plt.subplot(2, 2, i)\n",
    "                    plt.title(f'Class {cls}')\n",
    "                    plt.imshow(weights, cmap='viridis')\n",
    "#                    plt.colorbar()\n",
    "                    plt.axis('off')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                \n",
    "                # Save plot to a temporary file\n",
    "                temp_plot_path = os.path.join(output_dir, f'{save_prefix}_mnist_{(batch_idx+1)}.png')\n",
    "                torch.save(model.state_dict(), temp_plot_path.replace('.png', '.pt'))\n",
    "                plt.savefig(temp_plot_path)\n",
    "                plt.close()\n",
    "                \n",
    "                # Read the image and append to list\n",
    "                weight_images.append(imageio.imread(temp_plot_path))\n",
    "                print(batch_idx)\n",
    "                if batch_idx > 500:\n",
    "                    break\n",
    "    \n",
    "    # Save as GIF\n",
    "#    imageio.mimsave('../figures/mnist_weights_evolution.gif', weight_images, duration=0.5)\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = (-1)*model(data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    accuracy = correct / len(test_loader.dataset) * 100\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_164307/30739966.py:87: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  weight_images.append(imageio.imread(temp_plot_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "49\n",
      "59\n",
      "69\n",
      "79\n",
      "89\n",
      "99\n",
      "109\n",
      "119\n",
      "129\n",
      "139\n",
      "149\n",
      "159\n",
      "169\n",
      "179\n",
      "189\n",
      "199\n",
      "209\n",
      "219\n",
      "229\n",
      "239\n",
      "249\n",
      "259\n",
      "269\n",
      "279\n",
      "289\n",
      "299\n",
      "309\n",
      "319\n",
      "329\n",
      "339\n",
      "349\n",
      "359\n",
      "369\n",
      "379\n",
      "389\n",
      "399\n",
      "409\n",
      "419\n",
      "429\n",
      "439\n",
      "449\n",
      "459\n",
      "469\n",
      "479\n",
      "489\n",
      "499\n",
      "509\n",
      "Test Accuracy: 73.27%\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNN(harmonic=True).to(device)\n",
    "save_weight_visualization_gif(model, train_loader, test_loader, save_prefix='harmonic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_164307/30739966.py:87: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  weight_images.append(imageio.imread(temp_plot_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "49\n",
      "59\n",
      "69\n",
      "79\n",
      "89\n",
      "99\n",
      "109\n",
      "119\n",
      "129\n",
      "139\n",
      "149\n",
      "159\n",
      "169\n",
      "179\n",
      "189\n",
      "199\n",
      "209\n",
      "219\n",
      "229\n",
      "239\n",
      "249\n",
      "259\n",
      "269\n",
      "279\n",
      "289\n",
      "299\n",
      "309\n",
      "319\n",
      "329\n",
      "339\n",
      "349\n",
      "359\n",
      "369\n",
      "379\n",
      "389\n",
      "399\n",
      "409\n",
      "419\n",
      "429\n",
      "439\n",
      "449\n",
      "459\n",
      "469\n",
      "479\n",
      "489\n",
      "499\n",
      "509\n",
      "Test Accuracy: 67.38%\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNN(harmonic=False).to(device)\n",
    "save_weight_visualization_gif(model, train_loader, test_loader, save_prefix='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
